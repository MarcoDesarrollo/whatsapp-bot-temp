import os
import re
import logging
import unicodedata
import requests
import time
import ast
import tiktoken
from datetime import datetime, timedelta, timezone
from dotenv import load_dotenv
from flask import Flask, request
from openai import OpenAI
from supabase import create_client, Client
from twilio.rest import Client as TwilioClient
import numpy as np
from bot_config import BOT_PLANTILLAS
from bot_config import obtener_plantilla, validar_plantillas
from intencion_embeddings import analizar_intencion_con_embeddings
from kpi import registrar_kpi_evento
from aprendizaje import guardar_frase_conversion
import threading
from collections import defaultdict
import json
import difflib
from dateutil import parser 
from zoneinfo import ZoneInfo
from citas_bot import gestionar_reserva, actualizar_estado, manejar_confirmacion_o_zona, iniciar_citas_bot
from handlers.perfil_comportamiento import actualizar_perfil_comportamiento_usuario
from flask_cors import CORS
from flask import Flask, request

# === Helpers de env√≠o centralizados ===

def send_and_log(user_id, texto, conversation_id=None, tipo="text"):
    # 1) Env√≠o a WhatsApp
    twilio_client.messages.create(
        from_=TWILIO_WHATSAPP_NUMBER,
        to=f"whatsapp:{user_id}",
        body=texto
    )
    # 2) Log en Supabase
    supabase.from_("interaction_history").insert({
        "conversation_id": conversation_id,
        "sender_role": "bot",
        "message_type": tipo,
        "bot_response": texto,
        "start_time": datetime.now(timezone.utc).isoformat()
    }).execute()

MEXICO_TZ = ZoneInfo("America/Mexico_City")
ahora_mx = datetime.now(MEXICO_TZ)
fecha_actual_str = ahora_mx.strftime("%A %d de %B de %Y")
hora_actual_str = ahora_mx.strftime("%H:%M")


# Cargar variables de entorno
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
#TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
TWILIO_SID = os.getenv("TWILIO_ACCOUNT_SID")
TWILIO_AUTH = os.getenv("TWILIO_AUTH_TOKEN")
TWILIO_WHATSAPP_NUMBER = os.getenv("TWILIO_WHATSAPP_NUMBER")
FB_VERIFY_TOKEN = os.getenv("FB_VERIFY_TOKEN")
twilio_client = TwilioClient(TWILIO_SID, TWILIO_AUTH)

if os.getenv("ENV") == "development":
    print("üß™ Validando integridad de plantillas...")
    validar_plantillas()


# Inicializar servicios
client = OpenAI(api_key=OPENAI_API_KEY)
#telegram_bot = Bot(token=TELEGRAM_BOT_TOKEN)
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
app = Flask(__name__)
logging.basicConfig(level=logging.INFO)

# Estados
conversations = {}
estado_usuario = {}
ultimo_mensaje = {}

# Buffer para juntar mensajes si el usuario escribe en varias partes
mensaje_buffer = defaultdict(list)
hora_ultimo_buffer = {}

MINUTOS_PARA_CERRAR = 3



def guardar_conversacion_si_no_existe(user_id, numero, tipo_negocio="generico"):
    numero_limpio = numero.replace("+", "")
    try:
        existing = supabase.from_("conversation_history")\
            .select("conversation_id")\
            .eq("whatsapp_number", numero_limpio)\
            .limit(1)\
            .execute()
        
        if existing.data and len(existing.data) > 0:
            return existing.data[0]["conversation_id"]
        else:
            nueva = supabase.from_("conversation_history").insert({
                "whatsapp_number": numero_limpio,
                "channel": "whatsapp",
                "user_identifier": user_id,
                "user_id": user_id,
                "status": "bot",
                "is_human": False,
                "tipo_negocio": tipo_negocio  # ‚úÖ Aqu√≠ ya no marcar√° error
            }).execute()
            logging.info(f"üÜï Conversaci√≥n creada: {nueva}")
            return nueva.data[0]["conversation_id"] if nueva.data else None
    except Exception as e:
        logging.error(f"‚ùå Error accediendo a Supabase: {e}")
        return None


def guardar_mensaje_conversacion(conversation_id, mensaje, sender="user", tipo="text", file_url=None):
    if not conversation_id:
        logging.warning("‚ö†Ô∏è No se proporcion√≥ conversation_id. No se guardar√° el mensaje.")
        return None

    field_name = "user_message" if sender == "user" else "bot_response"
    insert_data = {
        "conversation_id": conversation_id,
        "sender_role": sender,
        "message_type": tipo,
        "start_time": datetime.now(timezone.utc).isoformat(),
        field_name: mensaje
    }

    # ‚úÖ Si hay una URL, agr√©gala al insert
    if file_url:
        insert_data["file_url"] = file_url

    try:
        nuevo = supabase.from_("interaction_history").insert(insert_data).execute()
        message_id = nuevo.data[0]["id"] if nuevo.data else None
        logging.info(f"üí¨ Mensaje guardado con ID: {message_id}")
        return message_id
    except Exception as e:
        logging.error(f"‚ùå Error guardando mensaje en interaction_history: {e}")
        return None


def buscar_fragmento_relevante(texto, top_k=3):
    try:
        # 1. Obtener embedding del texto
        embedding_res = client.embeddings.create(
            model="text-embedding-ada-002",
            input=texto
        )
        embedding_vector = embedding_res.data[0].embedding

        # 2. Ejecutar la funci√≥n RPC simple
        args_rpc = {
            "query_embedding": embedding_vector,
            "match_count": top_k
        }

        logging.info("üîé Buscando fragmentos relevantes en user_files...")

        response = supabase.rpc("match_user_files", args_rpc).execute()

        # 3. Validar resultado
        if not response.data:
            logging.warning("‚ö†Ô∏è No se encontraron fragmentos similares.")
            return []

        fragmentos = response.data

        for i, frag in enumerate(fragmentos):
            logging.info(f"üìÇ Fragmento #{i+1}: {frag.get('analysis_embedding_text', '')[:100]}...")

        return fragmentos

    except Exception as e:
        logging.error(f"‚ùå Error en b√∫squeda de fragmentos: {e}")
        return []


def detectar_cierre_conversacion(user_id, msg, ultimo_mensaje, tiempo_inactividad_min=10):
    now = datetime.now()
    texto = msg.strip().lower()
    FRASES_CIERRE = [
        "eso es todo", "ser√≠a todo", "me despido", "nos vemos", "adi√≥s",
        "puedes cerrar la conversaci√≥n", "no tengo m√°s dudas", "por el momento es todo",
        "hasta luego", "gracias por tu ayuda", "gracias por la informaci√≥n",
        "puedes finalizar", "puedes cerrar", "listo", "ya est√°", "ya qued√≥", "ok gracias"
    ]
    # Si detecta frase de cierre clara, cierra ya
    if any(f in texto for f in FRASES_CIERRE) and "?" not in texto:
        return "cerrar_ya"
    # Si hay inactividad
    if user_id in ultimo_mensaje:
        inactivo_por = now - ultimo_mensaje[user_id]
        if inactivo_por > timedelta(minutes=tiempo_inactividad_min):
            return "cerrar_ya"
    return "activa"


def generar_analisis_mensaje_unico(mensaje: str):
    try:
        prompt = """
Eres un analista de comportamiento para ventas.

Analiza el siguiente mensaje √∫nico del usuario y responde con:

Intenci√≥n: [inter√©s | duda | objeci√≥n | rechazo | sin intenci√≥n]  
Tono: [positivo | negativo | neutro]  
Relevancia: [alta | media | baja]  
Observaci√≥n: [1 l√≠nea con observaci√≥n √∫til para ventas]

Ejemplo de salida:  
Intenci√≥n: inter√©s  
Tono: positivo  
Relevancia: alta  
Observaci√≥n: Muestra inter√©s en cotizar un producto.
"""
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": mensaje}
            ],
            max_tokens=100,
            temperature=0.6
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logging.error(f"‚ùå Error en an√°lisis 1:1: {e}")
        return None


def generar_analisis_incremental(conversacion):
    try:
        prompt = """
Eres un analista de comportamiento de ventas.

Analiza este bloque de conversaci√≥n (usuario y bot) y resume en 1 l√≠nea:

- La intenci√≥n actual del usuario.
- C√≥mo ha cambiado el tono.
- Qu√© oportunidad comercial se detecta.

Formato:  
Intenci√≥n: [inter√©s | duda | objeci√≥n | rechazo | sin intenci√≥n]  
Tono: [positivo | negativo | neutro]  
Oportunidad: [frase breve con insight comercial]

Ejemplo:  
Intenci√≥n: duda  
Tono: neutro  
Oportunidad: Pidi√≥ informaci√≥n sobre garant√≠as del servicio.
"""
        full = "\n".join([f"{m['role'].capitalize()}: {m['content']}" for m in conversacion])
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": full}
            ],
            max_tokens=120,
            temperature=0.6
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logging.error(f"‚ùå Error en an√°lisis incremental: {e}")
        return None


def generar_analisis_final_openai(conversacion):
    try:
        full = "\n".join([f"{m['role'].capitalize()}: {m['content']}" for m in conversacion])
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": """
Eres un analista experto en marketing conversacional.

Con base en toda esta conversaci√≥n entre un usuario y un asistente virtual, responde de forma estructurada y clara los siguientes campos:

Resumen Final:
Intereses: [resumen claro]
Dudas frecuentes: [resumen claro]
Intenci√≥n de compra: [alta | media | baja | nula]
Observaciones para ventas: [m√°x 1 l√≠nea √∫til para seguimiento]
Tono: [positivo | negativo | neutro]
"""},
                {"role": "user", "content": full}
            ],
            max_tokens=500,
            temperature=0.6
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logging.error(f"Error generando an√°lisis final: {e}")
        return None

    
def clasificar_lead(conversacion, conversation_id):
    try:
        # Obtener configuraci√≥n del bot (incluye el contexto correcto)
        config = obtener_configuracion_bot(conversation_id)

        texto = "\n".join([f"{m['role'].capitalize()}: {m['content']}" for m in conversacion])

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": config["contexto"] + """

Ahora, clasifica este usuario como: calificado, medio o no calificado.

- calificado: Si cumple con los requisitos clave seg√∫n tu l√≥gica de negocio (ej. edad, inter√©s, documentos).
- medio: Si muestra inter√©s pero falta al menos un requisito.
- no calificado: Si no cumple con los m√≠nimos, no responde o no es relevante.

Responde solo con una palabra: calificado, medio o no calificado.
"""},  # Puedes mejorar esta l√≥gica por bot_type si deseas
                {"role": "user", "content": texto}
            ],
            max_tokens=10,
            temperature=0
        )

        return response.choices[0].message.content.strip().lower().replace(" ", "_")

    except Exception as e:
        logging.error(f"Error clasificando lead: {e}")
        return "no calificado"


def actualizar_etapa_conversacion(conversation_id, etapa):
    try:
        supabase.from_("conversation_history").update({
            "etapa_actual": etapa,
            "updated_at": datetime.now(timezone.utc).isoformat()
        }).eq("conversation_id", conversation_id).execute()
        logging.info(f"üîñ Etapa actualizada a '{etapa}' para conversaci√≥n {conversation_id}")
    except Exception as e:
        logging.error(f"‚ùå Error actualizando etapa_actual: {e}")


def actualizar_lead_score(conversation_id, score):
    try:
        supabase.from_("conversation_history").update({
            "lead_score": score,
            "updated_at": datetime.now(timezone.utc).isoformat()
        }).eq("conversation_id", conversation_id).execute()
        logging.info(f"üéØ Lead_score actualizado a '{score}'")
    except Exception as e:
        logging.error(f"‚ùå Error actualizando lead_score: {e}")


def reevaluar_lead_score_dinamico(conversation_id, conversacion, user_id):
    try:
        resultado = supabase.from_("conversation_history")\
            .select("lead_score")\
            .eq("conversation_id", conversation_id)\
            .limit(1)\
            .execute()

        score_actual = resultado.data[0]["lead_score"] if resultado.data else None
        nuevo_score = clasificar_lead(conversacion, conversation_id).strip().lower().replace(" ", "_")

        if nuevo_score and nuevo_score != (score_actual or "").strip().lower().replace(" ", "_"):
            actualizar_lead_score(conversation_id, nuevo_score)
            logging.info(f"üîÑ Lead_score actualizado: {score_actual} ‚Üí {nuevo_score}")

            # Evitar sobrescribir etapas clave como 'cotizacion_enviada' o 'seguimiento'
            etapa_actual = supabase.from_("conversation_history")\
                .select("etapa_actual")\
                .eq("conversation_id", conversation_id)\
               .limit(1).execute()
            etapa = etapa_actual.data[0]["etapa_actual"] if etapa_actual.data else None

            # Solo cambiar etapa si est√° en una etapa gen√©rica o inicial
            etapas_bloqueadas = ["cotizacion_enviada", "seguimiento"]
            if etapa not in etapas_bloqueadas:
                if nuevo_score in ["calificado", "medio"]:
                    actualizar_etapa_conversacion(conversation_id, "seguimiento")
                elif nuevo_score == "no_calificado":
                    actualizar_etapa_conversacion(conversation_id, "no_calificado")

            # Guardar historial
            try:
                supabase.from_("lead_score_history").insert({
                    "conversation_id": conversation_id,
                    "old_score": score_actual,
                    "new_score": nuevo_score,
                    "timestamp": datetime.now(timezone.utc).isoformat()
                }).execute()
                logging.info("üìà Historial de lead_score guardado correctamente")
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è No se pudo guardar historial de score: {e}")

            # Verifica que exista en conversation_history (fallback defensivo)
            try:
                existente = supabase.from_("conversation_history")\
                    .select("conversation_id")\
                    .eq("conversation_id", conversation_id)\
                    .limit(1)\
                    .execute()

                if not existente.data:
                    supabase.from_("conversation_history").insert({
                        "conversation_id": conversation_id,
                        "lead_score": nuevo_score,
                        "channel": "whatsapp",
                        "user_id": user_id,
                        "user_identifier": user_id,
                        "status": "bot",
                        "is_human": False,
                        "created_at": datetime.now(timezone.utc).isoformat()
                    }).execute()
                    logging.info("üìù Lead registrado tambi√©n en conversation_history")
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è No se pudo insertar en conversation_history: {e}")

    except Exception as e:
        logging.error(f"‚ùå Error reevaluando lead_score din√°micamente: {e}")



def send_messenger_message(sender_id, message):
    PAGE_ACCESS_TOKEN = os.getenv("FB_PAGE_ACCESS_TOKEN")
    url = f"https://graph.facebook.com/v17.0/me/messages?access_token={PAGE_ACCESS_TOKEN}"
    payload = {
        "recipient": {"id": sender_id},
        "message": {"text": message}
    }
    headers = {"Content-Type": "application/json"}
    try:
        r = requests.post(url, json=payload, headers=headers)
        r.raise_for_status()
        logging.info(f"‚úÖ Respuesta enviada a Messenger: {message}")
    except Exception as e:
        logging.error(f"‚ùå Error al enviar mensaje a Messenger: {e}")


def guardar_conversacion_messenger_si_no_existe(user_id, sender_id):
    try:
        existing = supabase.from_("conversation_history")\
            .select("conversation_id")\
            .eq("messenger_id", sender_id)\
            .limit(1)\
            .execute()

        if existing.data and len(existing.data) > 0:
            return existing.data[0]["conversation_id"]
        else:
            nueva = supabase.from_("conversation_history").insert({
                "messenger_id": sender_id,
                "channel": "messenger",
                "user_identifier": user_id,
                "user_id": user_id,
                "status": "bot",
                "is_human": False,
                "created_at": datetime.now(timezone.utc).isoformat()
            }).execute()
            logging.info(f"üÜï Conversaci√≥n Messenger creada: {nueva}")
            return nueva.data[0]["conversation_id"] if nueva.data else None
    except Exception as e:
        logging.error(f"‚ùå Error accediendo a Supabase (Messenger): {e}")
        return None



def construir_fragmento_resumido_por_tokens(fragmentos, max_tokens=7000, modelo="gpt-4"):
    encoding = tiktoken.encoding_for_model(modelo)
    bloques = []
    bloque_actual = ""
    tokens_actual = 0
    limite_seguro = max_tokens

    for frag in fragmentos:
        contenido = frag.get("analysis_embedding_text", "").strip()
        if not contenido:
            continue

        fragmento_texto = f"[Fragmento del proyecto]\n{contenido.strip()}\n"
        tokens_fragmento = len(encoding.encode(fragmento_texto))

        if tokens_actual + tokens_fragmento > limite_seguro:
            if bloque_actual:
                bloques.append(bloque_actual.strip())
            # Reiniciar nuevo bloque
            bloque_actual = fragmento_texto
            tokens_actual = tokens_fragmento
        else:
            bloque_actual += fragmento_texto
            tokens_actual += tokens_fragmento

    if bloque_actual:
        bloques.append(bloque_actual.strip())

    return bloques


def dividir_mensaje_largo(texto, max_chars=1500):
    partes = []
    while len(texto) > max_chars:
        corte = texto.rfind("\n", 0, max_chars)
        corte = corte if corte != -1 else max_chars
        partes.append(texto[:corte].strip())
        texto = texto[corte:].strip()
    partes.append(texto)
    return partes


def obtener_configuracion_bot(_conversation_id=None):
    try:
        config = supabase.from_("bot_configuracion")\
            .select("bot_type, tipo_negocio, ubicacion, latitud, longitud, contexto, tipo_reservas, negocio, requiere_zona, nombre_bot, zonas_permitidas")\
            .order("created_at", desc=False)\
            .limit(1)\
            .execute()

        if not config.data:
            raise Exception("‚ùå No se encontr√≥ ninguna configuraci√≥n del bot")

        datos = config.data[0]

        # Normalizar bot_type a lista
        bot_types = datos.get("bot_type", [])
        if not isinstance(bot_types, list):
            bot_types = [bot_types] if bot_types else ["ventas"]

        tipo_negocio = datos.get("tipo_negocio", "generico")  # ‚úÖ Extraer tipo de negocio

        # ‚úÖ Combinar funciones de todas las plantillas activas
        funciones_combinadas = set()
        usa_embeddings = False

        for tipo in bot_types:
            plantilla = BOT_PLANTILLAS.get(tipo, {})
            funciones_combinadas.update(plantilla.get("funciones", []))
            if plantilla.get("usa_embeddings"):
                usa_embeddings = True

        plantilla_base = {
            "descripcion": "Bot combinado",
            "funciones": list(funciones_combinadas)
        }

        return {
            "bot_type": bot_types,
            "tipo_negocio": tipo_negocio,  # ‚úÖ Incluir en retorno
            "ubicacion": datos.get("ubicacion", ""),
            "latitud": datos.get("latitud"),
            "longitud": datos.get("longitud"),
            "contexto": datos.get("contexto", ""),
            "tipo_reservas": datos.get("tipo_reservas", "√∫nico_horario"),
            "negocio": datos.get("negocio", "generico"),
            "requiere_zona": datos.get("requiere_zona", False),
            "zonas_permitidas": datos.get("zonas_permitidas", ["Sal√≥n", "Terraza", "VIP"]),
            "nombre_bot": datos.get("nombre_bot", "AIDANA"),
            "prompt": generar_prompt(
                plantilla_base,
                datos.get("contexto", ""),
                datos.get("nombre_bot", "Asistente"),
                tipo_negocio  # ‚úÖ Pasar tipo_negocio al prompt
            ),
            "usa_embeddings": usa_embeddings
        }

    except Exception as e:
        logging.error(f"‚ùå Fallback a ventas. Error: {e}")
        plantilla = BOT_PLANTILLAS["ventas"]
        return {
            "bot_type": ["ventas"],
            "tipo_negocio": "generico",
            "ubicacion": "",
            "latitud": None,
            "longitud": None,
            "contexto": "",
            "tipo_reservas": "√∫nico_horario",
            "negocio": "generico",
            "requiere_zona": False,
            "zonas_permitidas": ["Sal√≥n", "Terraza", "VIP"],
            "nombre_bot": "Asistente",
            "prompt": generar_prompt(plantilla, "", "Asistente", "generico"),
            "usa_embeddings": plantilla.get("usa_embeddings", False)
        }




def generar_prompt(plantilla, contexto_extra="", nombre_bot="Asistente", tipo_negocio="generico"):
    funciones = set(plantilla.get("funciones", []))

    instrucciones = [
        f"{plantilla['descripcion']} Hola, soy AIDANA, tu asistente virtual de {nombre_bot}."
        f"Este asistente est√° dise√±ado para un negocio tipo '{tipo_negocio}'.",
        "Act√∫a siempre con claridad y amabilidad. Tu prop√≥sito es asistir al usuario seg√∫n sus necesidades."
    ]

    if "agendar_reserva" in funciones:
        instrucciones.append("- Si el usuario quiere agendar una cita, demo o reserva, pide fecha, hora y zona (si aplica).")
    if "enviar_recordatorios" in funciones:
        instrucciones.append("- Env√≠a recordatorios antes de citas si es parte del flujo.")
    if "cancelar_reserva" in funciones:
        instrucciones.append("- Si el usuario desea cancelar, confirma y registra la cancelaci√≥n.")
    if "post_servicio" in funciones:
        instrucciones.append("- Despu√©s del servicio, puedes solicitar calificaci√≥n o hacer seguimiento.")
    if "calificar_leads" in funciones:
        instrucciones.append("- Si el usuario muestra inter√©s, calif√≠calo como lead y prop√≥n el siguiente paso.")
        instrucciones.append("- Si el usuario muestra inter√©s pero no decide, sugiere de forma amable un siguiente paso como agendar, cotizar o dejar sus datos.")
        instrucciones.append("- Si pregunta por precios o productos, ofrece ayudar con una propuesta o preguntar si desea m√°s detalles.")
        instrucciones.append("- Cierra tus respuestas con una acci√≥n sugerida siempre que sea posible: '¬øQuieres que te env√≠e una propuesta?', '¬øDeseas agendar tu cita ahora?', etc.")
    if "responder_por_embeddings" in funciones:
        instrucciones.append("- Si el usuario hace preguntas espec√≠ficas, usa los documentos entrenados para responder.")
    if "analizar_archivos" in funciones:
        instrucciones.append("- Si el usuario sube archivos, puedes analizarlos y dar retroalimentaci√≥n clara.")
    if "generar_faq" in funciones:
        instrucciones.append("- Si detectas una duda frecuente, puedes sugerir una respuesta tipo FAQ.")
    if "gestionar_tareas" in funciones:
        instrucciones.append("- Puedes organizar tareas si el usuario lo solicita.")
    if "crear_recordatorio" in funciones:
        instrucciones.append("- Puedes programar recordatorios seg√∫n lo que el usuario diga.")
    if "dar_seguimiento" in funciones:
        instrucciones.append("- Puedes dar seguimiento si el usuario no responde o deja algo pendiente.")
        instrucciones.append("- Si detectas que el usuario qued√≥ en pensar, preguntar o revisar algo, puedes recordarle amablemente despu√©s de unos minutos.")
        instrucciones.append("- Si el usuario pidi√≥ info y no ha respondido en un rato, puedes enviar un mensaje como: '¬øTuviste oportunidad de revisarlo? Estoy aqu√≠ para ayudarte.'")

    # Instrucciones generales
    instrucciones.append("- No digas frases gen√©ricas como 'estoy aqu√≠ para ayudarte'. S√© directo pero cordial.")
    instrucciones.append("- Si no tienes suficiente contexto, puedes pedirlo de forma amable.")

    prompt_final = "\n".join(instrucciones).strip()

    if contexto_extra:
        prompt_final += f"\n\n{contexto_extra.strip()}"

    return prompt_final



def generar_seguimiento_contextual(conversation_id):
    try:
        historial_res = supabase.from_("interaction_history")\
            .select("sender_role, user_message, bot_response")\
            .eq("conversation_id", conversation_id)\
            .order("start_time", desc=True)\
            .limit(6)\
            .execute()

        historial_raw = historial_res.data or []

        historial = []
        for item in reversed(historial_raw):
            if item.get("sender_role") == "user" and item.get("user_message"):
                historial.append({"role": "user", "content": item["user_message"]})
            elif item.get("sender_role") == "bot" and item.get("bot_response"):
                historial.append({"role": "assistant", "content": item["bot_response"]})

        if not historial:
            return None

        prompt = """
Eres un asistente virtual que busca dar seguimiento humano, c√°lido y natural a un usuario que no ha respondido en un tiempo.

Con base en el historial de los √∫ltimos mensajes, genera un mensaje breve, sutil y profesional para retomar la conversaci√≥n de forma amable. Evita sonar repetitivo o rob√≥tico. S√© claro, directo y personalizado.

Ejemplo (si el usuario pidi√≥ una cotizaci√≥n): 
"Hola, buen d√≠a. Solo quer√≠a saber si pudiste revisar la propuesta que te compartimos. Estoy aqu√≠ para ayudarte con cualquier duda."

No repitas el historial. Solo responde con el mensaje de seguimiento.
"""

        respuesta = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": "\n".join([f"{m['role']}: {m['content']}" for m in historial])}
            ],
            temperature=0.6,
            max_tokens=80
        )
        return respuesta.choices[0].message.content.strip()

    except Exception as e:
        logging.error(f"‚ùå Error generando seguimiento contextual: {e}")
        return None

def seguimiento_leads_silenciosos():
    print("‚è≥ Loop de seguimiento activo")

    mensajes_por_negocio = {
        "restaurante": "üçΩÔ∏è ¬øTe gustar√≠a confirmar tu reserva o consultar disponibilidad?",
        "clinica": "üë©‚Äç‚öïÔ∏è ¬øTuviste oportunidad de revisar sobre la consulta? Estoy aqu√≠ si quieres agendar.",
        "agencia": "üöó ¬øTe interesa agendar una cita o cotizar un auto? Estoy para ayudarte.",
        "software": "üíª ¬øPudiste revisar la propuesta? Estoy aqu√≠ si tienes dudas o quieres avanzar.",
        "marketing": "üì¢ ¬øTe gustar√≠a que revisemos juntos una estrategia? Podemos agendar.",
        "spa": "üíÜ‚Äç‚ôÄÔ∏è ¬øQuieres confirmar tu cita o saber m√°s de nuestros servicios?",
        "educacion": "üìö ¬øTe interesa apartar lugar o ver pr√≥ximos cursos?",
        "eventos": "üíç ¬øTe gustar√≠a cotizar o reservar tu evento con nosotros?",
        "ecommerce": "üõí ¬øPudiste ver los productos? Si necesitas ayuda con tu pedido, dime.",
        "hotel": "üè® ¬øA√∫n est√°s interesado en reservar alojamiento? Podemos ayudarte.",
        "legal": "‚öñÔ∏è ¬øPuedo asistirte con tu consulta legal o agendarte con un abogado?",
        "generico": "üëã Solo quer√≠a saber si pudiste revisar lo que te compart√≠. ¬øTe gustar√≠a que te ayude con algo m√°s?"
    }

    tiempos_por_lead_score = {
        "calificado": timedelta(hours=72),
        "medio": timedelta(hours=48),
        "no_calificado": timedelta(hours=24)
    }

    max_intentos = {
        "calificado": 3,
        "medio": 3,
        "no_calificado": 3
    }

    while True:
        try:
            ahora = datetime.now(timezone.utc)

            resultado = supabase.from_("conversation_history")\
                .select("conversation_id, user_id, updated_at, status, etapa_actual, tipo_negocio, lead_score, seguimiento_enviado_at, intentos_seguimiento, cotizacion_enviada_at, cotizacion_enviada")\
                .eq("status", "bot")\
                .execute()

            for conv in resultado.data or []:
                conversation_id = conv["conversation_id"]
                user_id = conv["user_id"]
                tipo = conv.get("tipo_negocio", "generico")
                etapa = conv.get("etapa_actual", "nuevo")
                lead_score = conv.get("lead_score", "no_calificado")
                seguimiento_at = conv.get("seguimiento_enviado_at")
                intentos = conv.get("intentos_seguimiento", 0) or 0
                ultima_interaccion = parser.isoparse(conv["updated_at"])
                cotizacion_enviada = conv.get("cotizacion_enviada", False)  # <-- SUMADO

                # ‚õîÔ∏è Si ya super√≥ los intentos para su tipo
                if intentos >= max_intentos.get(lead_score, 3):
                    continue

                # ‚è∞ Tiempo m√≠nimo de espera por lead
                tiempo_minimo = tiempos_por_lead_score.get(lead_score, timedelta(hours=24))
                if etapa == "cotizacion_enviada":
                    # SOLO hacer seguimiento si el booleano est√° en True
                    if not cotizacion_enviada:
                        continue  # üî¥ Salta si la cotizaci√≥n NO fue marcada como enviada
                    tiempo_minimo = timedelta(hours=72)  # 3 d√≠as

                # ‚è±Ô∏è Verificar si ya pas√≥ suficiente tiempo
                ultima_base = parser.isoparse(seguimiento_at) if seguimiento_at else ultima_interaccion
                if ahora - ultima_base < tiempo_minimo:
                    continue

                # üõë Usuario ya respondi√≥ despu√©s de la cotizaci√≥n
                cotizacion_enviada_at = conv.get("cotizacion_enviada_at")
                if cotizacion_enviada_at:
                    cotizacion_time = parser.isoparse(cotizacion_enviada_at)
                    if ultima_interaccion > cotizacion_time:
                        logging.info(f"üõë Usuario {user_id} ya respondi√≥ despu√©s de la cotizaci√≥n. No se enviar√° seguimiento.")
                        continue

                # üß† Intentar generar seguimiento contextual
                mensaje = generar_seguimiento_contextual(conversation_id)
                if not mensaje:
                    mensaje = mensajes_por_negocio.get(tipo, mensajes_por_negocio["generico"])
                    logging.warning(f"‚ö†Ô∏è Usando mensaje gen√©rico para seguimiento a {user_id}")

                 # üì§ Enviar mensaje y loguear
                send_and_log(user_id, mensaje, conversation_id, tipo="text")
                logging.info(f"üì¨ Seguimiento enviado a {user_id} (intento #{intentos + 1})")

                # üìù Registrar seguimiento
                supabase.from_("conversation_history").update({
                    "seguimiento_enviado_at": ahora.isoformat(),
                    "intentos_seguimiento": intentos + 1
                }).eq("conversation_id", conversation_id).execute()

        except Exception as e:
            logging.error(f"‚ùå Error en seguimiento a leads silenciosos: {e}")

        time.sleep(1800)  # ‚è≥ Esperar 30 minutos



def es_intencion_de_reservar(texto):
    texto = texto.lower()
    palabras_clave = [
        "reservar", "reserva", "agendar", "quiero una cita",
        "quiero hacer una cita", "quiero hacer una reserva",
        "agenda", "necesito una cita", "quiero agendar",
        "me puedes apartar", "quiero una mesa", "hacer cita"
    ]
    return any(palabra in texto for palabra in palabras_clave)

def es_intencion_reserva_por_embeddings(texto, threshold=0.80):
    try:
        embedding_usuario = client.embeddings.create(
            model="text-embedding-ada-002",
            input=texto
        ).data[0].embedding

        ejemplos_intencion = [
            "quiero reservar una cita",
            "c√≥mo agendo una consulta",
            "necesito un turno para ma√±ana",
            "quisiera apartar una hora",
            "c√≥mo hago una reserva"
        ]

        ejemplos_embeddings = client.embeddings.create(
            model="text-embedding-ada-002",
            input=ejemplos_intencion
        ).data

        for ej in ejemplos_embeddings:
            emb_ejemplo = ej.embedding
            similitud = cosine_similarity(embedding_usuario, emb_ejemplo)
            if similitud >= threshold:
                return True
        return False

    except Exception as e:
        logging.error(f"‚ùå Error usando embeddings para intenci√≥n de reserva: {e}")
        return False

def cosine_similarity(vec1, vec2):
    v1 = np.array(vec1)
    v2 = np.array(vec2)
    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))

def detectar_intencion_reserva(texto):
    if es_intencion_de_reservar(texto):
        return True

    # Solo si falla el filtro r√°pido, prueba con embeddings
    return es_intencion_reserva_por_embeddings(texto)


def detectar_intencion_comercial_o_reserva(msg, contexto_negocio=""):
    try:
        prompt_sistema = f"""
Eres un analista de intenciones para un asistente virtual.

Clasifica el siguiente mensaje como una de las siguientes opciones:
- venta ‚Üí si el usuario muestra inter√©s comercial, pide informaci√≥n, precios o contacto.
- reserva ‚Üí si quiere agendar una cita o hacer una reservaci√≥n.
- ambos ‚Üí si hace ambas cosas.
- ninguno ‚Üí si el mensaje no tiene intenci√≥n clara.

Ten en cuenta el siguiente contexto del negocio:
"{contexto_negocio}"

Responde √∫nicamente con: venta, reserva, ambos o ninguno.
"""
        respuesta = client.chat.completions.create(
            model="gpt-3.5-turbo",
            temperature=0.2,
            messages=[
                {"role": "system", "content": prompt_sistema.strip()},
                {"role": "user", "content": msg}
            ],
            max_tokens=5
        )

        return respuesta.choices[0].message.content.strip().lower()

    except Exception as e:
        logging.error(f"‚ùå Error detectando intenci√≥n: {e}")
        return "ninguno"


def obtener_funciones_disponibles(bot_type):
    funciones = set()
    if isinstance(bot_type, list):
        for tipo in bot_type:
            funciones.update(BOT_PLANTILLAS.get(tipo, {}).get("funciones", []))
    else:
        funciones.update(BOT_PLANTILLAS.get(bot_type, {}).get("funciones", []))
    return funciones


def obtener_historial_contexto(user_id, max_mensajes=40):
    return conversations.get(user_id, [])[-max_mensajes:]

def es_intencion_reagendar(texto):
    texto = texto.lower()
    frases = [
        "cambiar mi cita", "modificar mi cita", "reagendar", "reprogramar", 
        "mover la cita", "cambiar la hora", "otra hora", "otra fecha", 
        "cambiar fecha", "nueva fecha", "nueva hora", "ajustar cita", "editar cita"
    ]
    return any(frase in texto for frase in frases)


def obtener_reserva_activa(user_id):
    try:
        resultado = supabase.from_("reservaciones")\
            .select("id")\
            .eq("user_id", user_id)\
            .in_("estado", ["pendiente", "confirmada"])\
            .order("fecha_reserva", desc=True)\
            .limit(1)\
            .execute()
        return resultado.data[0] if resultado.data else None
    except Exception as e:
        logging.error(f"‚ùå Error buscando reserva activa: {e}")
        return None

def actualizar_reserva(reserva_id, nuevos_datos):
    try:
        resultado = supabase.from_("reservaciones").update(nuevos_datos)\
            .eq("id", reserva_id).execute()
        logging.info(f"üîÅ Reserva ACTUALIZADA (ID: {reserva_id}) con datos: {nuevos_datos}")
        return True
    except Exception as e:
        logging.error(f"‚ùå Error actualizando reserva (ID: {reserva_id}): {e}")
        return False





def procesar_buffer_usuario(user_id, nuevo_mensaje, ventana=10, max_mensajes=3):
    ahora = datetime.now()
    ultimo = hora_ultimo_buffer.get(user_id)

    # Si pas√≥ mucho tiempo desde el √∫ltimo ‚Üí reiniciamos buffer
    if not ultimo or (ahora - ultimo).seconds > ventana:
        mensaje_buffer[user_id] = [nuevo_mensaje]
    else:
        mensaje_buffer[user_id].append(nuevo_mensaje)

    hora_ultimo_buffer[user_id] = ahora

    # Si ya se juntaron suficientes mensajes, fusionamos y reiniciamos
    if len(mensaje_buffer[user_id]) >= max_mensajes:
        mensaje_completo = " ".join(mensaje_buffer[user_id]).strip()
        mensaje_buffer[user_id] = []
        return mensaje_completo

    # Si no hemos llegado al l√≠mite, solo mostramos el acumulado (pero no reiniciamos)
    return " ".join(mensaje_buffer[user_id]).strip()



def guardar_resumen_usuario(user_id, _conversation_id=None):
    try:
        logging.info(f"üîç Generando resumen para user_id: {user_id}")

        # 1. Buscar todas las conversaciones del usuario
        conversaciones_res = supabase.from_("conversation_history")\
            .select("conversation_id")\
            .ilike("user_id", f"%{user_id}")\
            .execute()

        conversaciones = conversaciones_res.data or []

        if not conversaciones:
            logging.warning(f"‚ö†Ô∏è No hay conversaciones para el usuario {user_id}")
            return

        conversation_ids = [c["conversation_id"] for c in conversaciones]

        # 2. Obtener interacciones de TODAS sus conversaciones
        interacciones_res = supabase.from_("interaction_history")\
            .select("sender_role, user_message, bot_response, start_time")\
            .in_("conversation_id", conversation_ids)\
            .order("start_time", desc=False)\
            .limit(200)\
            .execute()

        interacciones = interacciones_res.data or []

        if not interacciones:
            logging.warning("‚ö†Ô∏è No hay interacciones suficientes para resumir.")
            return

        # 3. Armar historial para GPT
        historial = []
        for i in interacciones:
            if i.get("sender_role") == "user" and i.get("user_message"):
                historial.append(f"Usuario: {i['user_message']}")
            elif i.get("sender_role") == "bot" and i.get("bot_response"):
                historial.append(f"Bot: {i['bot_response']}")

        texto_conversacion = "\n".join(historial[-50:])  # √öltimos 30 intercambios

        # 4. Generar resumen con GPT
        prompt = """
Resume de forma clara la intenci√≥n, temas tratados, objeciones y estilo del usuario.
El objetivo es guardar una memoria √∫til para futuras conversaciones.
Ejemplo:
Inter√©s en SUV, menciona presupuesto ajustado, desea agendar prueba. Usa lenguaje informal pero decidido.
"""
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": texto_conversacion}
            ],
            temperature=0.5,
            max_tokens=150
        )
        resumen = response.choices[0].message.content.strip()
        logging.info(f"üìù Resumen generado: {resumen}")

        # 5. Generar embedding
        embedding_response = client.embeddings.create(
            model="text-embedding-ada-002",
            input=resumen
        )
        vector = embedding_response.data[0].embedding

        # 6. Guardar en Supabase
        supabase.from_("user_summary_embeddings").insert({
            "user_id": user_id,
            "resumen_texto": resumen,
            "embedding_vector": vector
        }).execute()

        logging.info(f"üß† Resumen global de usuario guardado para {user_id}")

    except Exception as e:
        logging.error(f"‚ùå Error generando memoria del usuario: {e}")



def obtener_memoria_usuario(user_id, cuantos=3):
    try:
        resultado = supabase.from_("user_summary_embeddings")\
            .select("resumen_texto, created_at")\
            .eq("user_id", user_id)\
            .order("created_at", desc=True)\
            .limit(cuantos)\
            .execute()
        # Junta los res√∫menes de m√°s nuevo a m√°s viejo
        if resultado.data:
            return "\n".join([r["resumen_texto"] for r in reversed(resultado.data)])
        return None
    except Exception as e:
        logging.error(f"‚ùå Error obteniendo memoria del usuario: {e}")
        return None



def detectar_intencion_directa(texto, tipo):
    texto_normalizado = ''.join(
        c for c in unicodedata.normalize('NFD', texto.lower())
        if unicodedata.category(c) != 'Mn'
    )

    patrones = {
        "ubicacion": [
            "ubicacion", "direccion", "donde estan", "donde se ubican",
            "estan ubicados", "me puede mandar la ubicacion", "donde se encuentran"
        ],
        "horarios": [
            "horario", "a que hora", "cuando abren", "cuando cierran",
            "cual es su horario", "estan abiertos"
        ],
        "precios": [
            "precio", "cuanto cuesta", "tienen precios", "tarifas", "costo", "vale"
        ]
    }

    return any(p in texto_normalizado for p in patrones.get(tipo, []))

def enviar_ubicacion(usuario_id: str, ubicacion: str, lat: float = None, lng: float = None, conversation_id: str = None, config: dict = {}):
    try:
        if lat and lng:
            mensaje_texto = f"üìç Nuestra direcci√≥n es:\n{ubicacion}\n\nEnseguida te comparto la ubicaci√≥n en el mapa."
            # 1) env√≠o + log
            send_and_log(usuario_id, mensaje_texto, conversation_id, tipo="text")

            mensaje_mapa = "üó∫Ô∏è Da clic aqu√≠ para abrir el mapa:"
            # 2) Este queda directo porque necesita la acci√≥n geo
            twilio_client.messages.create(
                from_=TWILIO_WHATSAPP_NUMBER,
                to=f"whatsapp:{usuario_id}",
                persistent_action=[f"geo:{lat},{lng}|{ubicacion}"],
                body=mensaje_mapa
            )
            # y lo logueas manualmente como tipo "location":
            supabase.from_("interaction_history").insert({
                "conversation_id": conversation_id,
                "sender_role": "bot",
                "message_type": "location",
                "bot_response": mensaje_mapa,
                "file_url": f"https://www.google.com/maps?q={lat},{lng}",
                "start_time": datetime.now(timezone.utc).isoformat()
            }).execute()

        else:
            mensaje_texto = f"üìç Nuestra direcci√≥n es:\n{ubicacion}"
            send_and_log(usuario_id, mensaje_texto, conversation_id, tipo="text")

        logging.info(f"‚úÖ Ubicaci√≥n enviada correctamente a {usuario_id}")
    except Exception as e:
        logging.error(f"‚ùå Error al enviar ubicaci√≥n: {e}")



def generar_respuesta_promocion(texto_extraido: str) -> str:
    hoy = datetime.now().strftime("%d de %B de %Y")
    prompt = f"""
Eres un asistente de atenci√≥n al cliente amable y profesional. Tu tarea es analizar el siguiente texto de una imagen o PDF que podr√≠a contener una promoci√≥n.

Tu objetivo es:
1. Detectar si el texto contiene una promoci√≥n.
2. Si contiene promoci√≥n, indicar si est√° vigente al d√≠a de hoy ({hoy}).
3. Generar una respuesta NATURAL y amable para el cliente con base en lo anterior.

Instrucciones:
- Si est√° vigente, responde algo como:
  "üéâ ¬°Claro! Tenemos una promoci√≥n activa que sigue vigente: [resumen breve]."

- Si ya venci√≥, responde algo como:
  "üìå Esa promoci√≥n ya finaliz√≥, pero puedo ayudarte con otras opciones actuales."

- Si no es una promoci√≥n, responde algo como:
  "üßê No encontr√© informaci√≥n de promociones en ese archivo. ¬øQuieres que revise otra cosa?"

Texto para analizar:
\"\"\"{texto_extraido}\"\"\"
"""
    respuesta = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": prompt}
        ],
        max_tokens=200,
        temperature=0.5
    )
    return respuesta.choices[0].message.content.strip()


def obtener_ultimos_archivos(user_id, limite=3):
    try:
        resultado = supabase.from_("user_files")\
            .select("file_name, file_url, embedding_vector")\
            .eq("user_id", user_id)\
            .order("created_at", desc=True)\
            .limit(limite)\
            .execute()
        return resultado.data or []
    except Exception as e:
        logging.error(f"‚ùå Error al obtener archivos recientes: {e}")
        return []

def responder_y_salir(user_id: str, mensaje: str, conversation_id: str = None):
    # 1) Env√≠o + log en un √∫nico sitio
    send_and_log(user_id, mensaje, conversation_id, tipo="text")
    logging.info(f"üì§ Respuesta final enviada. Conversaci√≥n terminada.")
    return "ok", 200


def manejar_cierre_conversacion(user_id, msg, conversation_id, conversations, supabase):
    final = generar_analisis_final_openai(conversations[user_id])
    lead_score = clasificar_lead(conversations[user_id], conversation_id)
    actualizar_perfil_comportamiento_usuario(user_id, conversation_id)
    guardar_resumen_usuario(user_id, conversation_id)

    supabase.from_("conversation_history").update({
        "final_analysis": final,
        "status": "finalizado",
        "lead_score": lead_score,
        "updated_at": datetime.now(timezone.utc).isoformat()
    }).eq("conversation_id", conversation_id).execute()

    if lead_score in ["calificado", "medio"]:
        actualizar_etapa_conversacion(conversation_id, "seguimiento")
    elif lead_score == "no_calificado":
        actualizar_etapa_conversacion(conversation_id, "no_calificado")

    if lead_score in ["calificado", "medio"]:
        guardar_frase_conversion(user_id, msg, tipo="lead_calificado")
        registrar_kpi_evento(
            conversation_id=conversation_id,
            tipo_evento="lead_calificado",
            user_id=user_id
        )

    logging.info(f"üìä Lead clasificado como {lead_score} y etapa registrada.")
    return lead_score


def manejar_mensaje_promocional(user_id, mensaje_normalizado, conversation_id=None):
    palabras_clave = ["promocion", "promo", "descuento", "oferta", "rebaja"]
    if any(palabra in mensaje_normalizado for palabra in palabras_clave):
        archivos = obtener_ultimos_archivos(user_id)
        for archivo in archivos:
            texto_extraido = archivo.get("embedding_vector", "")
            if texto_extraido:
                respuesta = generar_respuesta_promocion(texto_extraido)
                if respuesta:
                    send_and_log(user_id, respuesta, conversation_id, tipo="text")
                    return True
    return False

def analizar_mensaje_individual(msg, message_id):
    try:
        single_analysis = generar_analisis_mensaje_unico(msg)
        if single_analysis:
            supabase.from_("interaction_history").update({
                "analysis_result": single_analysis
            }).eq("id", message_id).execute()

            embedding_response = client.embeddings.create(
                model="text-embedding-ada-002",
                input=msg
            )
            embedding_vector = embedding_response.data[0].embedding

            supabase.from_("interaction_history").update({
                "embedding_vector": embedding_vector
            }).eq("id", message_id).execute()
    except Exception as e:
        logging.error(f"‚ùå Error en an√°lisis incremental: {e}")

def verificar_y_guardar_calificacion(user_id, msg, conversation_id):
    try:
        etapa_actual = supabase.from_("conversation_history")\
            .select("etapa_actual")\
            .eq("conversation_id", conversation_id)\
            .limit(1).execute()

        if etapa_actual.data and etapa_actual.data[0]["etapa_actual"] == "esperando_calificacion":
            logging.info("üìù Usuario est√° en etapa de calificaci√≥n, intentando procesar...")

            # Usa GPT para extraer calificaci√≥n + comentario
            analisis = client.chat.completions.create(
                model="gpt-3.5-turbo",
                temperature=0.3,
                messages=[
                    {"role": "system", "content": "Extrae una calificacion del 1 al 5 y un comentario (si existe) del siguiente texto. Formato: Calificacion: 4\nComentario: Excelente trato.\nSi no hay comentario, escribe 'Comentario: null'"},
                    {"role": "user", "content": msg}
                ]
            )
            salida = analisis.choices[0].message.content.strip()
            match = re.search(r"Calificacion:\s*(\d)\s*Comentario:\s*(.*)", salida)

            if match:
                calificacion = int(match.group(1))
                comentario = match.group(2).strip()
                comentario = None if comentario.lower() == "null" else comentario

                # Buscar √∫ltima reserva del usuario
                reserva = supabase.from_("reservaciones")\
                    .select("id").eq("user_id", user_id)\
                    .order("fecha_reserva", desc=True).limit(1).execute()

                if reserva.data:
                    reserva_id = reserva.data[0]["id"]
                    supabase.from_("calificaciones").insert({
                        "reserva_id": reserva_id,
                        "user_id": user_id,
                        "calificacion": calificacion,
                        "comentario": comentario,
                        "canal": "whatsapp"
                    }).execute()

                    # Enviar respuesta de agradecimiento
                    send_and_log(
                        user_id,
                        "üôè ¬°Gracias por tu calificaci√≥n! Nos ayuda a mejorar continuamente.",
                        conversation_id
                    )

                    # Actualizar etapa
                    supabase.from_("conversation_history").update({
                        "etapa_actual": "calificacion_recibida"
                    }).eq("conversation_id", conversation_id).execute()
                    return True
            else:
                send_and_log(
                    user_id,
                    "‚ö†Ô∏è No pude entender bien tu calificaci√≥n. Por favor usa el formato:\n\nCalificaci√≥n: 5\nComentario: Excelente atenci√≥n.",
                    conversation_id
                )
                return True

        return False

    except Exception as e:
        logging.error(f"‚ùå Error verificando calificaci√≥n: {e}")
        return False

def obtener_perfil_comportamiento_usuario(user_id):
    try:
        perfil = supabase.from_("user_behavior_profile")\
            .select("*")\
            .eq("user_id", user_id)\
            .limit(1)\
            .execute()
        return perfil.data[0] if perfil.data else None
    except Exception as e:
        logging.error(f"‚ùå Error obteniendo perfil de comportamiento: {e}")
        return None

def get_config_fabrica():
    plantilla = BOT_PLANTILLAS["generico"]
    return {
        "bot_type": ["generico"],
        "tipo_negocio": "generico",
        "ubicacion": "",
        "latitud": None,
        "longitud": None,
        "contexto": "",
        "tipo_reservas": "√∫nico_horario",
        "negocio": "generico",
        "requiere_zona": False,
        "zonas_permitidas": [],
        "nombre_bot": "Asistente",
        "prompt": plantilla["prompt"],
        "usa_embeddings": plantilla.get("usa_embeddings", False)
    }


def generar_respuesta_openai(mensaje, prompt_base, temperature=0.7, model="gpt-3.5-turbo"):
    """
    Genera una respuesta usando OpenAI GPT con un prompt base.

    Args:
        mensaje (str): Mensaje recibido del usuario.
        prompt_base (str): Instrucci√≥n base para el asistente.
        temperature (float): Creatividad de la respuesta (0.0-1.0).
        model (str): Modelo de OpenAI a usar.

    Returns:
        str: Respuesta generada por la IA.
    """
    try:
        # Arma el historial para GPT (puedes ajustar el formato seg√∫n tus necesidades)
        mensajes = [
            {"role": "system", "content": prompt_base},
            {"role": "user", "content": mensaje}
        ]

        # Si usas la librer√≠a openai v1.x:
        response = client.chat.completions.create(
            model=model,
            messages=mensajes,
            temperature=temperature,
            max_tokens=300
        )
        texto = response.choices[0].message.content.strip()
        return texto

    except Exception as e:
        logging.error(f"‚ùå Error generando respuesta OpenAI: {e}")
        return "Perd√≥n, en este momento no puedo responder a tu pregunta. ¬øPuedes intentar de nuevo m√°s tarde?"

app = Flask(__name__)
CORS(app)
@app.route("/whatsapp", methods=['POST'])
def webhook():
    if not request.form:
        logging.warning("‚ö†Ô∏è Payload vac√≠o o no enviado como form-data")
        return "Se esperaba form-data (Twilio)", 400

    try:
        ya_respondio = False

        msg = request.form.get("Body", "").strip()
        sender = request.form.get("From", "").replace("whatsapp:", "")
        user_id = sender
        now = datetime.now()

        # ‚ö†Ô∏è Validar mensaje y remitente
        if not sender or not msg:
            logging.warning("‚ö†Ô∏è Faltan datos esenciales en el mensaje recibido.")
            return "Mensaje incompleto", 200


        # Verificar si hay estado pendiente de confirmaci√≥n o zona
        if manejar_confirmacion_o_zona(user_id, msg):
           return "ok", 200
        
        config = obtener_configuracion_bot()
        tipo_negocio = config.get("tipo_negocio", "generico")
          #Obtener o crear conversation_id primero
        conversation_id = guardar_conversacion_si_no_existe(user_id, sender, tipo_negocio)

        # 1Ô∏è‚É£ Intenci√≥n directa: ubicaci√≥n
        if detectar_intencion_directa(msg, "ubicacion"):
            ubicacion = config.get("ubicacion", "üìç Ubicaci√≥n no configurada.")
            enviar_ubicacion(
                usuario_id=user_id,
                ubicacion=ubicacion,
                lat=config.get("latitud"),
                lng=config.get("longitud"),
                conversation_id=conversation_id,
                config=config  # Puedes omitir si no lo usas
            )
            return "ok", 200

        
        # üîÅ Aplicar buffer inteligente
        msg = procesar_buffer_usuario(user_id, msg)
        
        logging.info(f"üì© Mensaje recibido de {sender}: {msg}")
        logging.info(f"üìÅ Registrando conversaci√≥n con tipo_negocio: {tipo_negocio}")
        
        # Inicializar historial si no existe
        if user_id not in conversations:
            conversations[user_id] = []

            # Saludo inicial personalizado
            nombre_empresa = config.get("nombre_bot", "tu empresa")
            saludo_inicial = (
                f"üëã ¬°Hola! Soy AIDANA, tu asistente virtual de confianza en {nombre_empresa}.\n\n"
                f"¬øEn qu√© puedo ayudarte hoy?\n"
                f"üí¨ Puedes preguntarme por:\n"
                f"‚Ä¢ Precios especiales\n"
                f"‚Ä¢ Modelos disponibles\n"
                f"‚Ä¢ Planes de financiamiento\n"
                f"‚Ä¢ Cotizaciones de seminuevos\n"
                f"‚Ä¢ Agendar una prueba de manejo\n"
            )
            # Validar si ya se envi√≥ el saludo anteriormente
            saludo_check = supabase.from_("conversation_history")\
                .select("primer_saludo_enviado")\
                .eq("conversation_id", conversation_id)\
                .limit(1)\
                .execute()
            
            if not saludo_check.data or not saludo_check.data[0]["primer_saludo_enviado"]:
                conversations[user_id].append({"role": "assistant", "content": saludo_inicial})
                supabase.from_("conversation_history").update({
                    "primer_saludo_enviado": True
                }).eq("conversation_id", conversation_id).execute()
        ultimo_mensaje[user_id] = now
        conversations[user_id].append({"role": "user", "content": msg})
        # Limitar historial a 7 mensajes como m√°ximo
        if len(conversations[user_id]) > 40:
            conversations[user_id] = conversations[user_id][-40:]


        # Intervenci√≥n humana
        intervencion = supabase.from_("conversation_history")\
            .select("is_human")\
            .eq("conversation_id", conversation_id)\
            .limit(1)\
            .execute()
        if intervencion.data and intervencion.data[0]["is_human"]:
            guardar_mensaje_conversacion(conversation_id, msg, sender="user", tipo="text")
            return "ok", 200

        message_id = guardar_mensaje_conversacion(conversation_id, msg, sender="user", tipo="text")
    

        etapa_actual = supabase.from_("conversation_history")\
            .select("etapa_actual")\
            .eq("conversation_id", conversation_id)\
            .limit(1).execute()

        if verificar_y_guardar_calificacion(user_id, msg, conversation_id):
            return "ok", 200
        # 3Ô∏è‚É£ Aqu√≠ va tu bloque de cierre de conversaci√≥n
        resultado_cierre = detectar_cierre_conversacion(user_id, msg, ultimo_mensaje)
        if resultado_cierre == "cerrar_ya":
            manejar_cierre_conversacion(user_id, msg, conversation_id, conversations, supabase)
            return responder_y_salir(sender, "‚úÖ ¬°Gracias por contactarnos! Conversaci√≥n finalizada. Si necesitas algo m√°s, escribe de nuevo.")

        # Media (im√°genes, archivos, etc.)
        num_media = int(request.form.get("NumMedia", 0))
        if num_media > 0:
            for i in range(num_media):
                media_url = request.form.get(f"MediaUrl{i}")
                media_type = request.form.get(f"MediaContentType{i}")
                tipo_archivo = "image" if media_type.startswith("image/") else "video" if media_type.startswith("video/") else "file"
                supabase.from_("interaction_history").insert({
                    "conversation_id": conversation_id,
                    "sender_role": "user",
                    "message_type": tipo_archivo,
                    "file_url": media_url,
                    "file_type": media_type,
                    "start_time": datetime.now(timezone.utc).isoformat()
                }).execute()
                logging.info(f"üìé Archivo recibido ({media_type}): {media_url}")

        # Lead score
        reevaluar_lead_score_dinamico(conversation_id, conversations[user_id], user_id)

        # üî§ Normalizar mensaje si a√∫n no existe
        mensaje_normalizado = ''.join(
            c for c in unicodedata.normalize('NFD', msg.lower())
            if unicodedata.category(c) != 'Mn'
        )
        logging.info(f"üß≠ Mensaje normalizado: {mensaje_normalizado}")
        # üîé Si el mensaje parece relacionado con promociones
        if manejar_mensaje_promocional(user_id, mensaje_normalizado):
            ya_respondio = True
            return "ok", 200

        if message_id:
            analizar_mensaje_individual(msg, message_id)



        # üß† Cargar config de plantilla
        config = obtener_configuracion_bot(conversation_id)
        # üß† Detectar intenci√≥n del mensaje
        intencion_detectada = detectar_intencion_comercial_o_reserva(msg, config.get("contexto", ""))
        logging.info(f"üß† Intenci√≥n detectada: {intencion_detectada}")

        nombre_bot = config.get("nombre_bot", "Asistente")
        if user_id in ultimo_mensaje and now - ultimo_mensaje[user_id] > timedelta(minutes=15):
           conversations[user_id].append({"role": "assistant", "content": f"Hola de nuevo, soy {nombre_bot}. Retomemos tu conversaci√≥n anterior..."})
        ultimo_mensaje[user_id] = now  # actualiza siempre despu√©s del saludo

        funciones = obtener_funciones_disponibles(config["bot_type"])


        # Reintento con embeddings si GPT no detect√≥ nada
        if intencion_detectada == "ninguno":
            # Probar con embeddings (si hay)
            if analizar_intencion_con_embeddings(msg, tipo="ventas", negocio=config.get("negocio", "generico")):
                intencion_detectada = "ventas"
                gestion_ok = gestionar_reserva(user_id, msg, sender, config, conversation_id)
                if gestion_ok:
                    return "ok", 200
                else:
                    # Aqu√≠ puedes mandar el prompt base de asistente AI
                    config_fabrica = get_config_fabrica()
                    send_and_log(
                        sender, 
                        "¬°Hola! Soy tu asistente virtual. ¬øEn qu√© puedo ayudarte? Puedes preguntarme cualquier cosa, aunque no tenga datos espec√≠ficos del negocio todav√≠a.", 
                        conversation_id, 
                        tipo="text"
                    )
                    return "ok", 200
            else:
                 # Fallback TOTAL: Reset config y contesta usando OpenAI
                config_fabrica = get_config_fabrica()
                respuesta_ai = generar_respuesta_openai(msg, config_fabrica["prompt"])
                send_and_log(sender, respuesta_ai, conversation_id, tipo="text")
                return "ok", 200

            

        # Registrar intenci√≥n detectada como KPI
        registrar_kpi_evento(
            conversation_id=conversation_id,
            tipo_evento=f"intencion_{intencion_detectada}",
            user_id=user_id
        )


        # üß† Si hay funci√≥n de agendar, y detecta reserva o ambos
        if "agendar_reserva" in funciones and intencion_detectada in ["reserva", "ambos"]:
            # Verificamos si el usuario dio alguna pista clara de fecha/hora
            hay_fecha_hora = re.search(
                r"(ma√±ana|hoy|lunes|martes|mi√©rcoles|jueves|viernes|s√°bado|domingo|\d{1,2}(:|\s)?(am|pm)?|\d{2}:\d{2})",
                msg, re.IGNORECASE
            )

            if hay_fecha_hora:
                # Si detecta pista, lanza reserva directamente
                gestion_ok = gestionar_reserva(user_id, msg, sender, config, conversation_id)
                if gestion_ok:
                    return "ok", 200
                else:
                     # Si no hay pista, solo responde con amabilidad y se pone a disposici√≥n
                     send_and_log(sender, f"¬°Hola! Soy AIDANA. ¬øEn qu√© puedo ayudarte hoy?", conversation_id, tipo="text")
                     ya_respondio = True
                     return "ok", 200


        # Preparar mensajes para OpenAI
        historial = obtener_historial_contexto(user_id)  # o m√°s si deseas m√°s contexto
        prompt_sistema = config["prompt"]

        # Si no hay archivo, elimina la parte de archivos del prompt
        num_media = int(request.form.get("NumMedia", 0))
        if num_media == 0:
            prompt_sistema = re.sub(r"- .*archivos.*\n?", "", prompt_sistema, flags=re.IGNORECASE)

        messages = [{"role": "system", "content": prompt_sistema}] + historial

        # --- üí° PERFIL DE COMPORTAMIENTO ---
        perfil = obtener_perfil_comportamiento_usuario(user_id)  # Debes crear esta funci√≥n tipo SELECT * ...
        if perfil:
            perfil_texto = f"""
        Perfil hist√≥rico del usuario:
        Lead score promedio: {perfil.get('lead_score_promedio', 'N/A')}
        Frases de inter√©s: {perfil.get('frases_interes', 'N/A')}
        Estilo: {perfil.get('estilo_mensaje', 'N/A')}
        D√≠as activo: {perfil.get('dias_activo', 'N/A')}
        """
            # Lo puedes insertar en segundo lugar o como system context
            messages.insert(1, {"role": "system", "content": perfil_texto})
        # üß† Recuperar memoria si existe
        memoria_usuario = obtener_memoria_usuario(user_id, cuantos=3)
        if memoria_usuario:
            try:
                # üß† Embedding del resumen
                embedding_resumen = client.embeddings.create(
                    model="text-embedding-ada-002",
                    input=memoria_usuario
                ).data[0].embedding

                # üß† Embedding del nuevo mensaje
                embedding_usuario = client.embeddings.create(
                    model="text-embedding-ada-002",
                    input=msg
                ).data[0].embedding

                # üßÆ Calcular similitud
                similitud = cosine_similarity(embedding_resumen, embedding_usuario)

                logging.info(f"üìä Similitud con memoria previa: {similitud:.2f}")

                if similitud > 0.65:
                    messages.insert(1, {"role": "system", "content": f"Contexto previo del usuario:\n{memoria_usuario}"})
                    logging.info("üß† Memoria insertada como contexto √∫til")
                else:
                    logging.info("üß† Memoria omitida (similitud baja)")

            except Exception as e:
                logging.error(f"‚ùå Error evaluando similitud con memoria: {e}")
        
        # Agregar fragmentos si usa embeddings
        if config["usa_embeddings"] and intencion_detectada in ["reserva", "venta", "ambos"]:
            fragmentos = buscar_fragmento_relevante(msg, top_k=10000) 
            bloques = construir_fragmento_resumido_por_tokens(fragmentos, max_tokens=7000, modelo="gpt-4")
            for i, bloque in enumerate(bloques):
                logging.info(f"üß† Bloque {i+1} insertado ({len(bloque)} chars)")
                messages.insert(2 + i, {"role": "system", "content": bloque})

        gpt_response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            temperature=0.6,
            max_tokens=500
        )
        bot_reply = gpt_response.choices[0].message.content.strip()
        # ‚ö†Ô∏è Elimina l√≠neas internas antes de enviar la respuesta
        bot_reply = re.sub(r"(?i)^calificacion:.*$", "", bot_reply, flags=re.MULTILINE).strip()
        bot_reply = re.sub(r"(?i)^comentario:.*$", "", bot_reply, flags=re.MULTILINE).strip()
        # Si no se gener√≥ una respuesta clara y la intenci√≥n era reserva
        if (not bot_reply or bot_reply.lower().startswith("lo siento")) and intencion_detectada in ["reserva", "ambos"]:
            logging.warning("‚ö†Ô∏è GPT no gener√≥ una respuesta √∫til. Forzando flujo de reserva.")
            return responder_y_salir(sender, "üóìÔ∏è Para agendar una demo, por favor dime qu√© d√≠a y hora te gustar√≠a. Tambi√©n ind√≠came si prefieres Zoom o presencial.")

        if ya_respondio:
            return "ok", 200

        if len(conversations[user_id]) > 7:
            conversations[user_id] = conversations[user_id][-7:]
        
        if bot_reply:
            guardar_mensaje_conversacion(conversation_id, bot_reply, sender="bot", tipo="text")
            # ‚úÖ Enviar respuesta al usuario
            twilio_client.messages.create(
                from_=TWILIO_WHATSAPP_NUMBER,
                to=f"whatsapp:{user_id}",
                body=bot_reply
            )
            logging.info(f"üì§ Mensaje enviado a {user_id}: {bot_reply}")

        # An√°lisis cada 4 mensajes
        if len(conversations[user_id]) % 4 == 0:
            insight = generar_analisis_incremental(conversations[user_id][-6:])
            if insight:
                supabase.from_("conversation_history").update({
                    "analysis_incremental": insight
                }).eq("conversation_id", conversation_id).execute()

        resultado_cierre = detectar_cierre_conversacion(user_id, msg, ultimo_mensaje)
        if resultado_cierre == "cerrar_ya":
            manejar_cierre_conversacion(user_id, msg, conversation_id, conversations, supabase)
            return responder_y_salir(sender, "‚úÖ ¬°Gracias por contactarnos! Conversaci√≥n finalizada. Si necesitas algo m√°s, escribe de nuevo.")


    except Exception as e:
        logging.error(f"‚ùå Error procesando mensaje: {e}")
        logging.exception("‚ùå Error general procesando mensaje:")
        return "Ocurri√≥ un error, intenta nuevamente.", 200
    # ‚úÖ Agrega esto fuera del try-except como fallback:
    return "ok", 200

app.add_url_rule("/actualizar_estado", view_func=actualizar_estado, methods=["POST", "OPTIONS"])
threading.Thread(target=seguimiento_leads_silenciosos, daemon=True).start()
if __name__ == '__main__':
    import citas_bot
    citas_bot.iniciar_citas_bot()
    app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 8080)), debug=True)

